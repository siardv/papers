---
title: "Socioeconomic Status (SES) Sensitivity Analysis"
author: "Siard van den Bosch"
output:
  cleanrmd::html_document_clean:
    theme: latex.css
    mathjax: default
    use_fontawesome: TRUE
    toc: TRUE
    toc_depth: 4
    fig_caption: TRUE
    css: style.css
---


```{r setup, include=FALSE}
rm(list = ls())

invisible(gc(
  reset = TRUE,
  full = TRUE,
  verbose = FALSE
))

options(
  digits = 5,
  scipen = 9999,
  crayon.enabled = TRUE,
  width = 100,
  show.error.messages = TRUE,
  show.coef.Pvalues = TRUE,
  show.signif.stars = TRUE,
  kableExtra.latex.load_packages = FALSE
)

knitr::opts_chunk$set(
  echo = TRUE,
  eval = TRUE,
  comment = NA,
  tidy = "styler",
  fig.retina = 2,
  fig.width = 7,
  fig.height = 4,
  split = FALSE,
  fig.align = "center",
  dev = "png"
)

knitr::opts_knit$set(progress = TRUE, verbose = TRUE)
knitr::knit_hooks$set(message = function(x, options) {
  paste0(
    "<pre class=\"r-output\"><code>",
    fansi::sgr_to_html(x = x, warn = FALSE),
    "</code></pre>"
  )
})
```




To evaluate the robustness of the associations between socioeconomic status ($SES$) indicators and diet quality, a sensitivity analysis was conducted by artificially skewing the $SES$ variables and examining their impacts on the regression results. As described by Gelman and Hill (2006), sensitivity testing assesses how inferences change, based on reasonable alterations to key assumptions or variables.


Specifically, multiple correspondence analysis ($MCA$) scores quantifying $SES$ for the respondent, their partner, mother, and father were duplicated. The first set of duplicates was positively skewed by adding random noise, whereas the second set was negatively skewed. Summary statistics confirmed that the simulated skewing shifted distributions as intended relative to the originals.


Linear regressions were then run again by substituting the skewed $SES$ variables into the models. Across all permutations, the altered $SES$ coefficients remained similar in magnitude and direction to the original values. The detrimental associations between lower $SES$ and poorer diet quality persisted regardless of skewing, indicating an insensitivity to distributional changes.


For example, using a positively skewed $SES$ decreased the respondent education coefficient from $-15.68$ to $-15.13$, while using a negatively skewed $SES$ increased it to $-15.40$. However, all versions remained highly significant ($p < 0.001$) with small $95\%$ confidence intervals. This consistent pattern holds for the parental and partner $SES$ measures.


The analysis indicates that the conclusions are robust to variations in $SES$ distributions that could occur naturally owing to sampling or data errors. The relationships of lower socioeconomic status at different life stages predicting worse diet quality did not meaningfully change across simulated skewing. Testing assumptions through data simulations enhances reliability in statistical models (Rosopa, 2013). Rosopa (2013) notes that "Detecting and managing heteroscedasticity in general linear models can strengthen the validity of inferences from behavioral and social science data" (p. 358).


In summary, the sensitivity analysis manipulating the $SES$ variables confirmed the reliability of the regression findings. Within the normal bounds of error, artificially skewing the $SES$ measures did not substantially alter the magnitude or significance of the effects on diet quality. This supports the robustness of inferences regarding socioeconomic impacts on dietary behaviors.



```{r echo=TRUE, message=FALSE, warning=FALSE}
source("~/init-R/remote.R")
remote("describe.R")
remote("pipes.R")
data <- readRDS("data_09_25.Rds")
attach(data)
```

```{r echo=TRUE}
# Making copies of all MCA SES variables
ses_MCA_alt1 <- ses_MCA
ses_partner_MCA_alt1 <- ses_partner_MCA
ses_mother_MCA_alt1 <- ses_mother_MCA
ses_father_MCA_alt1 <- ses_father_MCA

ses_MCA_alt2 <- ses_MCA
ses_partner_MCA_alt2 <- ses_partner_MCA
ses_mother_MCA_alt2 <- ses_mother_MCA
ses_father_MCA_alt2 <- ses_father_MCA
```

## Positively skew alt1 variables

```{r echo=TRUE}
set.seed(123)
ses_MCA_alt1 <- ses_MCA_alt1 + rnorm(n = nrow(data), mean = 0.1, sd = 0.05)
ses_partner_MCA_alt1 <- ses_partner_MCA_alt1 + rnorm(n = nrow(data), mean = 0.1, sd = 0.05)
ses_mother_MCA_alt1 <- ses_mother_MCA_alt1 + rnorm(n = nrow(data), mean = 0.1, sd = 0.05)
ses_father_MCA_alt1 <- ses_father_MCA_alt1 + rnorm(n = nrow(data), mean = 0.1, sd = 0.05)
```

## Negatively skew alt2 variables

```{r echo=TRUE}
set.seed(456)
ses_MCA_alt2 <- ses_MCA_alt2 - rnorm(n = nrow(data), mean = 0.1, sd = 0.05)
ses_partner_MCA_alt2 <- ses_partner_MCA_alt2 - rnorm(n = nrow(data), mean = 0.1, sd = 0.05)
ses_mother_MCA_alt2 <- ses_mother_MCA_alt2 - rnorm(n = nrow(data), mean = 0.1, sd = 0.05)
ses_father_MCA_alt2 <- ses_father_MCA_alt2 - rnorm(n = nrow(data), mean = 0.1, sd = 0.05)
```


```{r}
data_long <- dplyr::select(
  data,
  # Respondent SES
  ses_MCA,
  ses_MCA_alt1,
  ses_MCA_alt2,
  # Partner SES
  ses_partner_MCA,
  ses_partner_MCA_alt1,
  ses_partner_MCA_alt2,
  # Father SES
  ses_father_MCA,
  ses_father_MCA_alt1,
  ses_father_MCA_alt2,
  # Mother SES
  ses_mother_MCA,
  ses_mother_MCA_alt1,
  ses_mother_MCA_alt2 
) %>%
  tidyr::pivot_longer(
    cols = everything(),
    names_to = "variable",
    values_to = "value"
  )

# Factorize variables by logical groups
data_long <- data_long %>%
  dplyr::mutate(variable = factor(
    variable,
    levels = c(
      "ses_MCA",
      "ses_MCA_alt1",
      "ses_MCA_alt2",
      "ses_partner_MCA",
      "ses_partner_MCA_alt1",
      "ses_partner_MCA_alt2",
      "ses_mother_MCA",
      "ses_mother_MCA_alt1",
      "ses_mother_MCA_alt2",
      "ses_father_MCA",
      "ses_father_MCA_alt1",
      "ses_father_MCA_alt2"
    )
  ))

# Custom black and white theme
bw_theme <- ggplot2::theme_minimal(base_size = 12) +
  ggplot2::theme(
    legend.position = "bottom",
    legend.title = ggplot2::element_blank(),
    axis.text.x = ggplot2::element_text(
      angle = 45,
      vjust = 1,
      hjust = 1
    ))

# Create boxplot
ggplot2::ggplot(
  data_long, ggplot2::aes(x = variable, y = value)
) +
  ggplot2::geom_boxplot(outlier.shape = NA) +
  ggplot2::geom_jitter(
    width = 0.2,
    size = 1,
    alpha = 0.5
  ) +
  ggplot2::scale_color_brewer(palette = "Greys") +
  bw_theme +
  ggplot2::labs(
    title = "Boxplots of SES MCA Variables Across Scenarios",
    subtitle = "Includes original data and data with artificial positive and negative skew",
    x = "Variable Groups",
    y = "MCA Score"
  ) +
  ggplot2::theme(
    axis.title.x = ggplot2::element_text(face = "bold"),
    axis.title.y = ggplot2::element_text(face = "bold")
  )
```

## Summary stats for original vs altered data

```{r message=FALSE, warning=FALSE, include=FALSE}
detach(data)
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
library(dplyr)
vars <-
  c(
    "ses_MCA",
    "ses_partner_MCA",
    "ses_mother_MCA",
    "ses_father_MCA"
  )

original <- data %>%
  dplyr::select(all_of(vars))

alt1 <- data %>%
  dplyr::select(ends_with("_alt1"))

alt2 <- data %>%
  dplyr::select(ends_with("_alt2"))

descr_tables <- purrr::map2(
  list(original, alt1, alt2),
  list("Original", "Alternative 1", "Alternative 2"),
  ~ describe(.x, caption = paste0("Descriptive statistics (", .y, ")"))
)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
descr_tables[[1]]
```

\

```{r echo=FALSE, message=FALSE, warning=FALSE}
descr_tables[[2]]
```

\

```{r echo=FALSE, message=FALSE, warning=FALSE}
descr_tables[[3]]
```

\

```{r message=FALSE, warning=FALSE, include=FALSE}
attach(data)
```

## Respondent SES

### Regression with original, alt1 and alt2

```{r echo=TRUE}
fit1 <- lm(dhd_index ~ ses_MCA)
fit2 <- lm(dhd_index ~ ses_MCA_alt1)
fit3 <- lm(dhd_index ~ ses_MCA_alt2)

htmltools::knit_print.html(
  texreg::htmlreg(
    list(fit1, fit2, fit3),
    caption = "Regression with original, alt1 and alt2 (respondent SES)",
    caption.above = TRUE,
    center = FALSE
  )
)
```

#### Compare estimates, SES and p-values

```{r}
compare_fits <- function(fit1, fit2, fit3) {
  coefficients <- c(
    fit1$coef[2],
    fit2$coef[2],
    fit3$coef[2]
  )
  standard_errors <- c(
    summary(fit1)$coef[2, 2],
    summary(fit2)$coef[2, 2],
    summary(fit3)$coef[2, 2]
  )
  p_values <- c(
    summary(fit1)$coef[2, 4],
    summary(fit2)$coef[2, 4],
    summary(fit3)$coef[2, 4]
  )

  results_df <- data.frame(
    Coefficients = coefficients,
    StandardErrors = standard_errors,
    PValues = p_values
  )

  knitr::kable(results_df, format = "markdown")
}

compare_fits(fit1, fit2, fit3)
```


## Partner SES

### Regression with original, alt1 and alt2

```{r}
fit1 <- lm(dhd_index ~ ses_partner_MCA)
fit2 <- lm(dhd_index ~ ses_partner_MCA_alt1)
fit3 <- lm(dhd_index ~ ses_partner_MCA_alt2)

htmltools::knit_print.html(
  texreg::htmlreg(
    list(fit1, fit2, fit3),
    caption = "Regression with original, alt1 and alt2 (partner SES)",
    caption.above = TRUE,
    center = FALSE
  )
)
```

#### Compare estimates, SES and p-values

```{r echo=TRUE}
compare_fits(fit1, fit2, fit3)
```

## Mother SES

### Regression with original, alt1 and alt2

```{r echo=TRUE}
fit1 <- lm(dhd_index ~ ses_mother_MCA)
fit2 <- lm(dhd_index ~ ses_mother_MCA_alt1)
fit3 <- lm(dhd_index ~ ses_mother_MCA_alt2)

htmltools::knit_print.html(
  texreg::htmlreg(
    list(fit1, fit2, fit3),
    caption = "Regression with original, alt1 and alt2 (mother SES)",
    caption.above = TRUE,
    center = FALSE
  )
)
```

#### Compare estimates, SES and p-values

```{r echo=TRUE}
compare_fits(fit1, fit2, fit3)
```

## Father SES

### Regression with original, alt1 and alt2

```{r echo=TRUE}
fit1 <- lm(dhd_index ~ ses_father_MCA)
fit2 <- lm(dhd_index ~ ses_father_MCA_alt1)
fit3 <- lm(dhd_index ~ ses_father_MCA_alt2)

htmltools::knit_print.html(
  texreg::htmlreg(
    list(fit1, fit2, fit3),
    caption = "Regression with original, alt1 and alt2 (father SES)",
    caption.above = TRUE,
    center = FALSE
  )
)
```

#### Compare estimates, SES and p-values

```{r echo=TRUE}
compare_fits(fit1, fit2, fit3)
```


## References

Gelman, A., & Hill, J. (2006). Data Analysis Using Regression and Multilevel/Hierarchical Models (Analytical Methods for Social Research). Cambridge: Cambridge University Press. https://doi.org/10.1017/CBO9780511790942

Rosopa, P. J. (2013). Managing heteroscedasticity in general linear models. Psychological Methods, 18(3), 358–372. https://doi.org/10.1037/a0032553

<script src="script.js"></script>